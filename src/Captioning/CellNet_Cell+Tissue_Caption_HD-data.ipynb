{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gdown (if not already installed)\n",
    "#!pip install gdown --upgrade --quiet\n",
    "\n",
    "# install OpenAI API\n",
    "#!pip install openai\n",
    "\n",
    "# install tiktoken to count tokens\n",
    "#!pip install tiktoken\n",
    "\n",
    "# install package to handle tiff files \n",
    "#!pip install tifffile\n",
    "\n",
    "#%pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWGfnsdfI-Xn",
    "outputId": "5e5a77a3-27ac-4e0a-d3f6-c2de6df62046"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "import base64\n",
    "import shutil\n",
    "import hashlib\n",
    "import tifffile\n",
    "import tiktoken\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_uDJ2KB3-rnj"
   },
   "outputs": [],
   "source": [
    "def process_llm_output(input_text, caption_width=80):\n",
    "    # Split the input text into fields and caption\n",
    "    fields_text, caption_text = input_text.split(\"**Caption:**\")\n",
    "\n",
    "    # Process fields into bullet points\n",
    "    fields_lines = fields_text.strip().split(\"\\n\")\n",
    "    processed_fields = \"Example Fields:\\n\"\n",
    "    for line in fields_lines:\n",
    "        if \":\" in line:\n",
    "            key, value = line.split(\":\", 1)\n",
    "            processed_fields += f\"- {key.strip()}: {value.strip()}\\n\"\n",
    "\n",
    "    # Wrap the caption\n",
    "    wrapped_caption = textwrap.fill(caption_text.strip(), width=caption_width)\n",
    "\n",
    "    # Combine processed fields and wrapped caption\n",
    "    formatted_output = f\"{processed_fields}\\nCaption:\\n{wrapped_caption}\"\n",
    "    return formatted_output\n",
    "\n",
    "def count_tokens(text, model=\"gpt-4o\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVrvlZvE2W5M"
   },
   "outputs": [],
   "source": [
    "openai_api_key = \"your_token_here\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "example_caption = (\n",
    "    \"[Image 11]: This single cell is a podocyte, obtained from a mouse kidney using Visium \"\n",
    "    \"HD technology. Podocytes are crucial for the glomerular filtration barrier, \" \n",
    "    \"characterized by elongated foot processes that tightly adhere to glomerular \" \n",
    "    \"capillaries, forming a highly selective filtration interface. Unlike previous \" \n",
    "    \"samples, this region exhibits a more loosely arranged tissue structure, with \" \n",
    "    \"distinct gaps between cells and a high density of dark-stained nuclei \" \n",
    "    \"surrounding the glomerulus. The image also shows numerous red blood cells, \" \n",
    "    \"indicating abundant blood flow essential for sustaining efficient filtration. \" \n",
    "    \"Additionally, some podocytes appear morphologically irregular, potentially \" \n",
    "    \"undergoing structural remodeling to adapt to pressure changes. Podocyte \" \n",
    "    \"injury can lead to proteinuria and glomerulosclerosis, significantly \" \n",
    "    \"compromising kidney filtration function.\"\n",
    ")\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a helpful, knowledgeable assistant who will explain the \"\n",
    "    \"morphology of the cell image visible in the histopathology tissue patch. \"\n",
    "    \"You must utilize the visual cues in the images and textual cues from given \"\n",
    "    \"metadata. Also, include only ONE caption per image. Separate each caption \" \n",
    "    \"with the image number like `[Image #]`. Here is a sample caption for your reference: \" \n",
    "    f\"'{example_caption}'\"\n",
    ")\n",
    "\n",
    "# Cell and Tissue Metadata\n",
    "#  - [0]: cell type \n",
    "#  - [1]: cell disease state \n",
    "#  - [2]: tissue\n",
    "#  - [3]: tissue disease state\n",
    "#  - [4]: source (mouse or human)\n",
    "#  - [5]: st technology\n",
    "def cell_tissue_user_prompt(metadata):\n",
    "    return (\n",
    "        \"Generate a concise, biologically accurate caption that describes the cellular morphology, including \"\n",
    "        \"shape, size, structure, and function of the cell in the histopathology tissue patch. The \" \n",
    "        f\"single cell image is a {'cancerous' if metadata[1]=='1' else 'non-cancerous'} {metadata[0]} cell. \"\n",
    "        f\"It is located in the {metadata[4]}\\'s {metadata[2]}, \"\n",
    "        f\"which is {'cancerous' if metadata[3]=='1' else 'not cancerous'}. The images were \"\n",
    "        f\"obtained using {metadata[5]} spatial transcriptomics technology.\"\n",
    "    )\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9YdA5kvUruH",
    "outputId": "f0a8ed9a-53a9-4413-c4af-999474a6ea58"
   },
   "outputs": [],
   "source": [
    "def load_data(root_dir):\n",
    "    all_prompts = []\n",
    "    all_images = []\n",
    "    all_cell_ids = []\n",
    "    all_metadata = []\n",
    "\n",
    "    expected_cols = [\n",
    "        \"cell-type\",\n",
    "        \"cell disease state\",\n",
    "        \"tissue\",\n",
    "        \"tissue disease state\",\n",
    "        \"source\",\n",
    "        \"st technology\"\n",
    "    ]\n",
    "\n",
    "    folders = sorted(os.listdir(root_dir))\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(root_dir, folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        point_id = folder  # e.g., point_13442\n",
    "        cell_img = os.path.join(folder_path, f\"{point_id}.png\")\n",
    "        tissue_img = os.path.join(folder_path, f\"{point_id}_tissue.png\")\n",
    "        attr_path = os.path.join(folder_path, \"attribute.csv\")\n",
    "\n",
    "        if not (os.path.exists(cell_img) and os.path.exists(tissue_img) and os.path.exists(attr_path)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(attr_path)\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            row = df.iloc[0]\n",
    "            if not all(col in row for col in expected_cols):\n",
    "                continue\n",
    "\n",
    "            metadata = [str(row[col]) for col in expected_cols]\n",
    "            prompt = cell_tissue_user_prompt(metadata)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {folder} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "        all_cell_ids.append(point_id)\n",
    "        all_metadata.append(metadata)\n",
    "        all_prompts.append(prompt)\n",
    "        all_images.append([cell_img, tissue_img])\n",
    "\n",
    "    return all_cell_ids, all_metadata, all_prompts, all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(cell_ids, metadata_list, prompts, images, batch_size=10):\n",
    "    batches = []\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch = (\n",
    "            cell_ids[i:i+batch_size],\n",
    "            metadata_list[i:i+batch_size],\n",
    "            prompts[i:i+batch_size],\n",
    "            images[i:i+batch_size]\n",
    "        )\n",
    "        batches.append(batch)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def append_to_csv(csv_path, cell_ids, metadata_list, captions):\n",
    "    header = [\"cell_id\", \"cell-type\", \"cell disease state\", \"tissue\",\n",
    "              \"tissue disease state\", \"source\", \"st technology\", \"caption\"]\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write header once\n",
    "        if not file_exists:\n",
    "            writer.writerow(header)\n",
    "\n",
    "        for cid, meta, cap in zip(cell_ids, metadata_list, captions):\n",
    "            writer.writerow([cid] + meta + [cap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_llm_request(client, system_prompt, prompt_list, image_lists):\n",
    "    \"\"\"\n",
    "    Sends a single GPT-4o request containing multiple (prompt + 2 images) entries.\n",
    "\n",
    "    Parameters:\n",
    "        client: OpenAI client\n",
    "        system_prompt: str, system message with task definition\n",
    "        prompt_list: list of strings, user prompts for each cell-tissue pair\n",
    "        image_lists: list of [cell_img_path, tissue_img_path] for each entry\n",
    "\n",
    "    Returns:\n",
    "        response: OpenAI API response\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    user_content = []\n",
    "\n",
    "    for i, (prompt, image_pair) in enumerate(zip(prompt_list, image_lists)):\n",
    "        cell_img_path, tissue_img_path = image_pair\n",
    "\n",
    "        # Add prompt text with identifier\n",
    "        user_content.append({\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"[Image Pair {i+1}] {prompt}\"\n",
    "        })\n",
    "\n",
    "        # Add cell image\n",
    "        user_content.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{encode_image(cell_img_path)}\"\n",
    "            }\n",
    "        })\n",
    "\n",
    "        # Add tissue image\n",
    "        user_content.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{encode_image(tissue_img_path)}\"\n",
    "            }\n",
    "        })\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            messages=messages\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch request: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uj_-yTrY5kwD"
   },
   "outputs": [],
   "source": [
    "def run_captioning_pipeline(root_dir, batch_size=10, save_path=\"captions_output_a.csv\"):\n",
    "    cell_ids, metadata_list, prompts, image_paths = load_data(root_dir)\n",
    "    print(f\"Loaded {len(prompts)} valid entries.\")\n",
    "\n",
    "    batches = create_batches(cell_ids, metadata_list, prompts, image_paths, batch_size=batch_size)\n",
    "\n",
    "    responses = []\n",
    "    token_counts = []\n",
    "\n",
    "    for idx, (cid_batch, meta_batch, prompt_batch, image_batch) in enumerate(batches):\n",
    "        print(f\"\\nBatch #{idx+1}/{len(batches)}\")\n",
    "        response = batch_llm_request(client, system_prompt, prompt_batch, image_batch)\n",
    "        responses.append(response)\n",
    "\n",
    "        if response:\n",
    "            # Extract captions\n",
    "            text = response.choices[0].message.content\n",
    "            captions = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "\n",
    "            if len(captions) != len(cid_batch):\n",
    "                print(f\"⚠️ Warning: Mismatch in caption count (got {len(captions)}, expected {len(cid_batch)}). Skipping save.\")\n",
    "                continue\n",
    "\n",
    "            # Save to CSV\n",
    "            append_to_csv(save_path, cid_batch, meta_batch, captions)\n",
    "            print(f\"✅ Batch {idx+1} saved to {save_path}\")\n",
    "\n",
    "            # Track token usage\n",
    "            if hasattr(response, \"usage\"):\n",
    "                tokens = response.usage.total_tokens\n",
    "                token_counts.append(tokens)\n",
    "                print(f\"Tokens used: {tokens}\")\n",
    "        else:\n",
    "            print(f\"❌ Batch {idx+1} failed. Response is None.\")\n",
    "\n",
    "    return responses, token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "maiW23trXSOo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 valid entries.\n",
      "\n",
      "Batch #1/100\n",
      "✅ Batch 1 saved to captions_output.csv\n",
      "Tokens used: 6648\n",
      "\n",
      "Batch #2/100\n",
      "✅ Batch 2 saved to captions_output.csv\n",
      "Tokens used: 6750\n",
      "\n",
      "Batch #3/100\n",
      "✅ Batch 3 saved to captions_output.csv\n",
      "Tokens used: 6717\n",
      "\n",
      "Batch #4/100\n",
      "✅ Batch 4 saved to captions_output.csv\n",
      "Tokens used: 6739\n",
      "\n",
      "Batch #5/100\n",
      "✅ Batch 5 saved to captions_output.csv\n",
      "Tokens used: 6717\n",
      "\n",
      "Batch #6/100\n",
      "✅ Batch 6 saved to captions_output.csv\n",
      "Tokens used: 6732\n",
      "\n",
      "Batch #7/100\n",
      "✅ Batch 7 saved to captions_output.csv\n",
      "Tokens used: 6768\n",
      "\n",
      "Batch #8/100\n",
      "✅ Batch 8 saved to captions_output.csv\n",
      "Tokens used: 6753\n",
      "\n",
      "Batch #9/100\n",
      "✅ Batch 9 saved to captions_output.csv\n",
      "Tokens used: 6761\n",
      "\n",
      "Batch #10/100\n",
      "✅ Batch 10 saved to captions_output.csv\n",
      "Tokens used: 6814\n",
      "\n",
      "Batch #11/100\n",
      "✅ Batch 11 saved to captions_output.csv\n",
      "Tokens used: 6713\n",
      "\n",
      "Batch #12/100\n",
      "✅ Batch 12 saved to captions_output.csv\n",
      "Tokens used: 6724\n",
      "\n",
      "Batch #13/100\n",
      "✅ Batch 13 saved to captions_output.csv\n",
      "Tokens used: 6825\n",
      "\n",
      "Batch #14/100\n",
      "✅ Batch 14 saved to captions_output.csv\n",
      "Tokens used: 6730\n",
      "\n",
      "Batch #15/100\n",
      "✅ Batch 15 saved to captions_output.csv\n",
      "Tokens used: 6719\n",
      "\n",
      "Batch #16/100\n",
      "✅ Batch 16 saved to captions_output.csv\n",
      "Tokens used: 6790\n",
      "\n",
      "Batch #17/100\n",
      "✅ Batch 17 saved to captions_output.csv\n",
      "Tokens used: 6710\n",
      "\n",
      "Batch #18/100\n",
      "✅ Batch 18 saved to captions_output.csv\n",
      "Tokens used: 6827\n",
      "\n",
      "Batch #19/100\n",
      "✅ Batch 19 saved to captions_output.csv\n",
      "Tokens used: 6725\n",
      "\n",
      "Batch #20/100\n",
      "✅ Batch 20 saved to captions_output.csv\n",
      "Tokens used: 6806\n",
      "\n",
      "Batch #21/100\n",
      "✅ Batch 21 saved to captions_output.csv\n",
      "Tokens used: 6757\n",
      "\n",
      "Batch #22/100\n",
      "✅ Batch 22 saved to captions_output.csv\n",
      "Tokens used: 6716\n",
      "\n",
      "Batch #23/100\n",
      "✅ Batch 23 saved to captions_output.csv\n",
      "Tokens used: 6876\n",
      "\n",
      "Batch #24/100\n",
      "✅ Batch 24 saved to captions_output.csv\n",
      "Tokens used: 6825\n",
      "\n",
      "Batch #25/100\n",
      "✅ Batch 25 saved to captions_output.csv\n",
      "Tokens used: 6770\n",
      "\n",
      "Batch #26/100\n",
      "✅ Batch 26 saved to captions_output.csv\n",
      "Tokens used: 6689\n",
      "\n",
      "Batch #27/100\n",
      "✅ Batch 27 saved to captions_output.csv\n",
      "Tokens used: 6691\n",
      "\n",
      "Batch #28/100\n",
      "✅ Batch 28 saved to captions_output.csv\n",
      "Tokens used: 6767\n",
      "\n",
      "Batch #29/100\n",
      "✅ Batch 29 saved to captions_output.csv\n",
      "Tokens used: 6780\n",
      "\n",
      "Batch #30/100\n",
      "✅ Batch 30 saved to captions_output.csv\n",
      "Tokens used: 6698\n",
      "\n",
      "Batch #31/100\n",
      "✅ Batch 31 saved to captions_output.csv\n",
      "Tokens used: 6745\n",
      "\n",
      "Batch #32/100\n",
      "✅ Batch 32 saved to captions_output.csv\n",
      "Tokens used: 6714\n",
      "\n",
      "Batch #33/100\n",
      "✅ Batch 33 saved to captions_output.csv\n",
      "Tokens used: 6827\n",
      "\n",
      "Batch #34/100\n",
      "✅ Batch 34 saved to captions_output.csv\n",
      "Tokens used: 6708\n",
      "\n",
      "Batch #35/100\n",
      "✅ Batch 35 saved to captions_output.csv\n",
      "Tokens used: 6811\n",
      "\n",
      "Batch #36/100\n",
      "✅ Batch 36 saved to captions_output.csv\n",
      "Tokens used: 6733\n",
      "\n",
      "Batch #37/100\n",
      "✅ Batch 37 saved to captions_output.csv\n",
      "Tokens used: 6710\n",
      "\n",
      "Batch #38/100\n",
      "✅ Batch 38 saved to captions_output.csv\n",
      "Tokens used: 6821\n",
      "\n",
      "Batch #39/100\n",
      "✅ Batch 39 saved to captions_output.csv\n",
      "Tokens used: 6719\n",
      "\n",
      "Batch #40/100\n",
      "✅ Batch 40 saved to captions_output.csv\n",
      "Tokens used: 6791\n",
      "\n",
      "Batch #41/100\n",
      "✅ Batch 41 saved to captions_output.csv\n",
      "Tokens used: 6696\n",
      "\n",
      "Batch #42/100\n",
      "✅ Batch 42 saved to captions_output.csv\n",
      "Tokens used: 6714\n",
      "\n",
      "Batch #43/100\n",
      "✅ Batch 43 saved to captions_output.csv\n",
      "Tokens used: 6705\n",
      "\n",
      "Batch #44/100\n",
      "✅ Batch 44 saved to captions_output.csv\n",
      "Tokens used: 6779\n",
      "\n",
      "Batch #45/100\n",
      "✅ Batch 45 saved to captions_output.csv\n",
      "Tokens used: 6685\n",
      "\n",
      "Batch #46/100\n",
      "✅ Batch 46 saved to captions_output.csv\n",
      "Tokens used: 6782\n",
      "\n",
      "Batch #47/100\n",
      "✅ Batch 47 saved to captions_output.csv\n",
      "Tokens used: 6720\n",
      "\n",
      "Batch #48/100\n",
      "✅ Batch 48 saved to captions_output.csv\n",
      "Tokens used: 6922\n",
      "\n",
      "Batch #49/100\n",
      "✅ Batch 49 saved to captions_output.csv\n",
      "Tokens used: 6778\n",
      "\n",
      "Batch #50/100\n",
      "✅ Batch 50 saved to captions_output.csv\n",
      "Tokens used: 6665\n",
      "\n",
      "Batch #51/100\n",
      "✅ Batch 51 saved to captions_output.csv\n",
      "Tokens used: 6705\n",
      "\n",
      "Batch #52/100\n",
      "✅ Batch 52 saved to captions_output.csv\n",
      "Tokens used: 6766\n",
      "\n",
      "Batch #53/100\n",
      "✅ Batch 53 saved to captions_output.csv\n",
      "Tokens used: 6776\n",
      "\n",
      "Batch #54/100\n",
      "✅ Batch 54 saved to captions_output.csv\n",
      "Tokens used: 6770\n",
      "\n",
      "Batch #55/100\n",
      "✅ Batch 55 saved to captions_output.csv\n",
      "Tokens used: 6832\n",
      "\n",
      "Batch #56/100\n",
      "✅ Batch 56 saved to captions_output.csv\n",
      "Tokens used: 6746\n",
      "\n",
      "Batch #57/100\n",
      "✅ Batch 57 saved to captions_output.csv\n",
      "Tokens used: 6794\n",
      "\n",
      "Batch #58/100\n",
      "✅ Batch 58 saved to captions_output.csv\n",
      "Tokens used: 6821\n",
      "\n",
      "Batch #59/100\n",
      "✅ Batch 59 saved to captions_output.csv\n",
      "Tokens used: 6747\n",
      "\n",
      "Batch #60/100\n",
      "✅ Batch 60 saved to captions_output.csv\n",
      "Tokens used: 6742\n",
      "\n",
      "Batch #61/100\n",
      "✅ Batch 61 saved to captions_output.csv\n",
      "Tokens used: 6759\n",
      "\n",
      "Batch #62/100\n",
      "✅ Batch 62 saved to captions_output.csv\n",
      "Tokens used: 6687\n",
      "\n",
      "Batch #63/100\n",
      "✅ Batch 63 saved to captions_output.csv\n",
      "Tokens used: 6696\n",
      "\n",
      "Batch #64/100\n",
      "✅ Batch 64 saved to captions_output.csv\n",
      "Tokens used: 6774\n",
      "\n",
      "Batch #65/100\n",
      "✅ Batch 65 saved to captions_output.csv\n",
      "Tokens used: 6823\n",
      "\n",
      "Batch #66/100\n",
      "✅ Batch 66 saved to captions_output.csv\n",
      "Tokens used: 6921\n",
      "\n",
      "Batch #67/100\n",
      "✅ Batch 67 saved to captions_output.csv\n",
      "Tokens used: 6797\n",
      "\n",
      "Batch #68/100\n",
      "✅ Batch 68 saved to captions_output.csv\n",
      "Tokens used: 6764\n",
      "\n",
      "Batch #69/100\n",
      "✅ Batch 69 saved to captions_output.csv\n",
      "Tokens used: 6812\n",
      "\n",
      "Batch #70/100\n",
      "✅ Batch 70 saved to captions_output.csv\n",
      "Tokens used: 6786\n",
      "\n",
      "Batch #71/100\n",
      "✅ Batch 71 saved to captions_output.csv\n",
      "Tokens used: 6810\n",
      "\n",
      "Batch #72/100\n",
      "✅ Batch 72 saved to captions_output.csv\n",
      "Tokens used: 6835\n",
      "\n",
      "Batch #73/100\n",
      "✅ Batch 73 saved to captions_output.csv\n",
      "Tokens used: 6777\n",
      "\n",
      "Batch #74/100\n",
      "✅ Batch 74 saved to captions_output.csv\n",
      "Tokens used: 6730\n",
      "\n",
      "Batch #75/100\n",
      "✅ Batch 75 saved to captions_output.csv\n",
      "Tokens used: 6672\n",
      "\n",
      "Batch #76/100\n",
      "✅ Batch 76 saved to captions_output.csv\n",
      "Tokens used: 6786\n",
      "\n",
      "Batch #77/100\n",
      "✅ Batch 77 saved to captions_output.csv\n",
      "Tokens used: 6764\n",
      "\n",
      "Batch #78/100\n",
      "✅ Batch 78 saved to captions_output.csv\n",
      "Tokens used: 6747\n",
      "\n",
      "Batch #79/100\n",
      "✅ Batch 79 saved to captions_output.csv\n",
      "Tokens used: 6643\n",
      "\n",
      "Batch #80/100\n",
      "✅ Batch 80 saved to captions_output.csv\n",
      "Tokens used: 6680\n",
      "\n",
      "Batch #81/100\n",
      "✅ Batch 81 saved to captions_output.csv\n",
      "Tokens used: 6739\n",
      "\n",
      "Batch #82/100\n",
      "✅ Batch 82 saved to captions_output.csv\n",
      "Tokens used: 6777\n",
      "\n",
      "Batch #83/100\n",
      "✅ Batch 83 saved to captions_output.csv\n",
      "Tokens used: 6807\n",
      "\n",
      "Batch #84/100\n",
      "✅ Batch 84 saved to captions_output.csv\n",
      "Tokens used: 6726\n",
      "\n",
      "Batch #85/100\n",
      "✅ Batch 85 saved to captions_output.csv\n",
      "Tokens used: 6735\n",
      "\n",
      "Batch #86/100\n",
      "✅ Batch 86 saved to captions_output.csv\n",
      "Tokens used: 6698\n",
      "\n",
      "Batch #87/100\n",
      "✅ Batch 87 saved to captions_output.csv\n",
      "Tokens used: 6746\n",
      "\n",
      "Batch #88/100\n",
      "✅ Batch 88 saved to captions_output.csv\n",
      "Tokens used: 6774\n",
      "\n",
      "Batch #89/100\n",
      "✅ Batch 89 saved to captions_output.csv\n",
      "Tokens used: 6732\n",
      "\n",
      "Batch #90/100\n",
      "✅ Batch 90 saved to captions_output.csv\n",
      "Tokens used: 6668\n",
      "\n",
      "Batch #91/100\n",
      "✅ Batch 91 saved to captions_output.csv\n",
      "Tokens used: 6798\n",
      "\n",
      "Batch #92/100\n",
      "✅ Batch 92 saved to captions_output.csv\n",
      "Tokens used: 6784\n",
      "\n",
      "Batch #93/100\n",
      "✅ Batch 93 saved to captions_output.csv\n",
      "Tokens used: 6698\n",
      "\n",
      "Batch #94/100\n",
      "✅ Batch 94 saved to captions_output.csv\n",
      "Tokens used: 6680\n",
      "\n",
      "Batch #95/100\n",
      "✅ Batch 95 saved to captions_output.csv\n",
      "Tokens used: 6700\n",
      "\n",
      "Batch #96/100\n",
      "✅ Batch 96 saved to captions_output.csv\n",
      "Tokens used: 6807\n",
      "\n",
      "Batch #97/100\n",
      "✅ Batch 97 saved to captions_output.csv\n",
      "Tokens used: 6826\n",
      "\n",
      "Batch #98/100\n",
      "✅ Batch 98 saved to captions_output.csv\n",
      "Tokens used: 6784\n",
      "\n",
      "Batch #99/100\n",
      "✅ Batch 99 saved to captions_output.csv\n",
      "Tokens used: 6672\n",
      "\n",
      "Batch #100/100\n",
      "✅ Batch 100 saved to captions_output.csv\n",
      "Tokens used: 6707\n"
     ]
    }
   ],
   "source": [
    "root_path = \"../../../../../extra/zhanglab0/xil43/HD/a/point/\"\n",
    "\n",
    "responses, token_counts = run_captioning_pipeline(root_path, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletion(id='chatcmpl-BY16F4WcTzuIX31eKV6D00eeMwcXx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"1. This single cell is a podocyte from a non-cancerous mouse kidney, captured using Visium HD technology. Podocytes exhibit distinctive foot processes crucial for the glomerular filtration barrier. The tissue section shows a dense arrangement of these cells around glomerular structures, with dark-stained nuclei and well-defined cytoplasmic extensions.\\n\\n2. This non-cancerous proximal tubule cell from a mouse kidney is visualized using Visium HD technology. Proximal tubule cells have abundant cytoplasm and a brush border for reabsorption. The tissue section depicts tightly packed tubular cells with elongated nuclei, indicative of active transport and filtration function.\\n\\n3. This is a podocyte from a non-cancerous mouse kidney, imaged with Visium HD technology. Podocytes form the filtration barrier with their interdigitating foot processes. The histological section reveals a dense clustering of podocytes with prominent nuclei and visible capillary loops, demonstrating their role in filtration.\\n\\n4. The image features a non-cancerous proximal tubule cell from a mouse kidney obtained through Visium HD technology. These cells are characterized by a prominent brush border for reabsorption. The surrounding tissue shows tightly aligned tubules with well-defined lumens and nuclei, supporting the kidney's filtering system.\\n\\n5. This image shows a podocyte from a non-cancerous mouse kidney, captured with Visium HD technology. Podocytes are integral to the filtration barrier, displaying complex foot processes. The tissue section highlights podocyte-rich regions with dense nuclei and interspersed capillaries essential for kidney function.\\n\\n6. The cell depicted is a podocyte from a non-cancerous mouse kidney, visualized using Visium HD technology. Podocytes' unique foot processes are crucial for filtration. The image shows an orderly arrangement of these cells with distinct nuclei around capillary loops, underscoring their filtration role.\\n\\n7. This image captures a podocyte from a non-cancerous mouse kidney using Visium HD technology. These cells exhibit specialized foot processes vital for the glomerular filtration barrier. The tissue panel reveals densely packed podocytes with prominent nuclei, surrounded by capillary networks.\\n\\n8. The highlighted cell is a podocyte from a non-cancerous mouse kidney, observed with Visium HD technology. Podocytes possess unique foot processes essential for their filtration function. The broader tissue section shows a cluster of these cells with visible nuclei and associated capillaries.\\n\\n9. This image features a podocyte from a non-cancerous mouse kidney, obtained via Visium HD technology. Characterized by intricate foot processes, podocytes contribute significantly to filtration. The tissue section displays a dense aggregation of podocytes with prominent nuclei adjacent to capillary loops.\\n\\n10. The captured cell is a podocyte from a non-cancerous mouse kidney, visualized with Visium HD technology. Podocytes are key to forming the filtration barrier, with their foot processes visible in the tissue. The surrounding area shows a dense matrix of podocytes with well-defined nuclei, illustrating their role in maintaining renal filtration.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1747447079, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_9bddfca6e2', usage=CompletionUsage(completion_tokens=616, prompt_tokens=6082, total_tokens=6698, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(this_batch):\n",
    "    print(f\"Prompt: {this_batch[0]}\")\n",
    "    image_paths = this_batch[1]\n",
    "    \n",
    "    num_subplots = len(image_paths)\n",
    "    fig, axes = plt.subplots(math.ceil(num_subplots/10), 10, figsize=(10,3))  # 2 rows, 5 columns\n",
    "    axes = axes.flatten()  # make it easier to index\n",
    "    for i, path in enumerate(image_paths):\n",
    "        img = Image.open(path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'Image {i+1}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#this_batch = batches[3]\n",
    "#show_batch(this_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHu66n18bRTz",
    "outputId": "881d55a3-8783-4f41-b832-4facf61a684f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['. This single cell is a podocyte from a non-cancerous mouse kidney, captured using Visium HD technology. Podocytes exhibit distinctive foot processes crucial for the glomerular filtration barrier. The tissue section shows a dense arrangement of these cells around glomerular structures, with dark-stained nuclei and well-defined cytoplasmic extensions.',\n",
       " '. This non-cancerous proximal tubule cell from a mouse kidney is visualized using Visium HD technology. Proximal tubule cells have abundant cytoplasm and a brush border for reabsorption. The tissue section depicts tightly packed tubular cells with elongated nuclei, indicative of active transport and filtration function.',\n",
       " '. This is a podocyte from a non-cancerous mouse kidney, imaged with Visium HD technology. Podocytes form the filtration barrier with their interdigitating foot processes. The histological section reveals a dense clustering of podocytes with prominent nuclei and visible capillary loops, demonstrating their role in filtration.',\n",
       " \". The image features a non-cancerous proximal tubule cell from a mouse kidney obtained through Visium HD technology. These cells are characterized by a prominent brush border for reabsorption. The surrounding tissue shows tightly aligned tubules with well-defined lumens and nuclei, supporting the kidney's filtering system.\",\n",
       " '. This image shows a podocyte from a non-cancerous mouse kidney, captured with Visium HD technology. Podocytes are integral to the filtration barrier, displaying complex foot processes. The tissue section highlights podocyte-rich regions with dense nuclei and interspersed capillaries essential for kidney function.',\n",
       " \". The cell depicted is a podocyte from a non-cancerous mouse kidney, visualized using Visium HD technology. Podocytes' unique foot processes are crucial for filtration. The image shows an orderly arrangement of these cells with distinct nuclei around capillary loops, underscoring their filtration role.\",\n",
       " '. This image captures a podocyte from a non-cancerous mouse kidney using Visium HD technology. These cells exhibit specialized foot processes vital for the glomerular filtration barrier. The tissue panel reveals densely packed podocytes with prominent nuclei, surrounded by capillary networks.',\n",
       " '. The highlighted cell is a podocyte from a non-cancerous mouse kidney, observed with Visium HD technology. Podocytes possess unique foot processes essential for their filtration function. The broader tissue section shows a cluster of these cells with visible nuclei and associated capillaries.',\n",
       " '. This image features a podocyte from a non-cancerous mouse kidney, obtained via Visium HD technology. Characterized by intricate foot processes, podocytes contribute significantly to filtration. The tissue section displays a dense aggregation of podocytes with prominent nuclei adjacent to capillary loops.',\n",
       " '. The captured cell is a podocyte from a non-cancerous mouse kidney, visualized with Visium HD technology. Podocytes are key to forming the filtration barrier, with their foot processes visible in the tissue. The surrounding area shows a dense matrix of podocytes with well-defined nuclei, illustrating their role in maintaining renal filtration.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_responses = [response.choices[0].message.content for response in responses]\n",
    "llm_outputs = ' '.join(text_responses)\n",
    "#outputs = [x for x in re.split(r'###|\\d+\\.', llm_outputs) if x.strip()]\n",
    "#text_responses = [x for x in re.split(r'\\n\\n', llm_outputs) if x.strip()]\n",
    "#text_responses = [x for x in re.split(r'\\d+', llm_outputs) if x.strip()]\n",
    "outputs = []\n",
    "for text_resp in text_responses:\n",
    "    indiv = [x.strip() for x in re.split(r'\\d+', text_resp) if len(x) > 10]\n",
    "    outputs += indiv    \n",
    "        \n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8n6RwM5hm0A",
    "outputId": "b9b1aa99-88f2-4f72-8a98-81f810dc16c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  # of images: 498\n",
      "# of captions: 498\n",
      "Data saved to Captions/captions_50b_10sz_20-29_dirs.csv\n"
     ]
    }
   ],
   "source": [
    "# Define CSV file path\n",
    "csv_filename = f\"Captions/captions_{num_batches}b_{batch_size}sz_{start_dir_idx}-{end_dir_idx-1}_dirs.csv\"\n",
    "\n",
    "# Identify rows to be removed (indices of captions that contain \"unable\" or \"blank\")\n",
    "rows_to_be_removed = [i for i, resp in enumerate(outputs) if \"unable\" in resp or \"blank\" in resp]\n",
    "\n",
    "# Extract valid captions (removing those in `rows_to_be_removed`)\n",
    "captions = [resp for i, resp in enumerate(outputs) if i not in rows_to_be_removed]\n",
    "\n",
    "# Flatten image_dict to [(directory, image), ...]\n",
    "image_list = [(directory, image) for directory, images in image_dict.items() for image in images]\n",
    "\n",
    "# Filter images based on the same indices in `rows_to_be_removed`\n",
    "filtered_image_list = [img for i, img in enumerate(image_list) if i not in rows_to_be_removed]\n",
    "\n",
    "# Ensure there are enough captions for the images\n",
    "num_images = len(filtered_image_list)\n",
    "num_captions = len(captions)\n",
    "\n",
    "print(\"  # of images:\", num_images)\n",
    "print(\"# of captions:\", num_captions)\n",
    "\n",
    "if num_captions < num_images:\n",
    "    print(f\"Warning: Fewer captions ({num_captions}) than images ({num_images}). Some images will be left without captions.\")\n",
    "elif num_captions > num_images:\n",
    "    print(f\"Warning: More captions ({num_captions}) than images ({num_images}). Some captions will be unused.\")\n",
    "\n",
    "\n",
    "# Ensure both lists have the same length by truncating to the minimum size\n",
    "min_length = min(len(filtered_image_list), len(captions))\n",
    "filtered_image_list = filtered_image_list[:min_length]\n",
    "captions = captions[:min_length]\n",
    "\n",
    "# Pair filtered images with captions\n",
    "paired_data = [\n",
    "    (dir_dict[directory], image.split(\"/\")[-1], captions[i])\n",
    "    for i, (directory, image) in enumerate(filtered_image_list)\n",
    "]\n",
    "\n",
    "# Write to CSV\n",
    "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Directory_Name\", \"Patch_Name\", \"Caption\"])  # Header\n",
    "    writer.writerows(paired_data)\n",
    "\n",
    "print(f\"Data saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
