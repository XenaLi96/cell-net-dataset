{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gdown (if not already installed)\n",
    "#!pip install gdown --upgrade --quiet\n",
    "\n",
    "# install OpenAI API\n",
    "#!pip install openai\n",
    "\n",
    "# install tiktoken to count tokens\n",
    "#!pip install tiktoken\n",
    "\n",
    "# install package to handle tiff files \n",
    "#!pip install tifffile\n",
    "\n",
    "#%pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWGfnsdfI-Xn",
    "outputId": "5e5a77a3-27ac-4e0a-d3f6-c2de6df62046"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "import base64\n",
    "import shutil\n",
    "import hashlib\n",
    "import tempfile\n",
    "import tifffile\n",
    "import tiktoken\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tif_to_png(tif_path):\n",
    "    image_array = tifffile.imread(tif_path)\n",
    "\n",
    "    # Normalize to 8-bit\n",
    "    if image_array.dtype != np.uint8:\n",
    "        image_array = np.clip(image_array, 0, 255)\n",
    "        image_array = (image_array / image_array.max() * 255).astype(np.uint8)\n",
    "\n",
    "    # Shape handling\n",
    "    if len(image_array.shape) == 2:\n",
    "        pil_image = Image.fromarray(image_array, mode='L')\n",
    "    elif image_array.shape[2] >= 3:\n",
    "        pil_image = Image.fromarray(image_array[:, :, :3], mode='RGB')\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported image shape: {image_array.shape}\")\n",
    "\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".png\")\n",
    "    pil_image.save(temp_file.name, \"PNG\")\n",
    "    return temp_file.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_uDJ2KB3-rnj"
   },
   "outputs": [],
   "source": [
    "def process_llm_output(input_text, caption_width=80):\n",
    "    # Split the input text into fields and caption\n",
    "    fields_text, caption_text = input_text.split(\"**Caption:**\")\n",
    "\n",
    "    # Process fields into bullet points\n",
    "    fields_lines = fields_text.strip().split(\"\\n\")\n",
    "    processed_fields = \"Example Fields:\\n\"\n",
    "    for line in fields_lines:\n",
    "        if \":\" in line:\n",
    "            key, value = line.split(\":\", 1)\n",
    "            processed_fields += f\"- {key.strip()}: {value.strip()}\\n\"\n",
    "\n",
    "    # Wrap the caption\n",
    "    wrapped_caption = textwrap.fill(caption_text.strip(), width=caption_width)\n",
    "\n",
    "    # Combine processed fields and wrapped caption\n",
    "    formatted_output = f\"{processed_fields}\\nCaption:\\n{wrapped_caption}\"\n",
    "    return formatted_output\n",
    "\n",
    "def count_tokens(text, model=\"gpt-4o\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVrvlZvE2W5M"
   },
   "outputs": [],
   "source": [
    "openai_api_key = \"your_token_here\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "example_caption = (\n",
    "    \"[Image 11]: This single cell is a podocyte, obtained from a mouse kidney using Visium \"\n",
    "    \"HD technology. Podocytes are crucial for the glomerular filtration barrier, \" \n",
    "    \"characterized by elongated foot processes that tightly adhere to glomerular \" \n",
    "    \"capillaries, forming a highly selective filtration interface. Unlike previous \" \n",
    "    \"samples, this region exhibits a more loosely arranged tissue structure, with \" \n",
    "    \"distinct gaps between cells and a high density of dark-stained nuclei \" \n",
    "    \"surrounding the glomerulus. The image also shows numerous red blood cells, \" \n",
    "    \"indicating abundant blood flow essential for sustaining efficient filtration. \" \n",
    "    \"Additionally, some podocytes appear morphologically irregular, potentially \" \n",
    "    \"undergoing structural remodeling to adapt to pressure changes. Podocyte \" \n",
    "    \"injury can lead to proteinuria and glomerulosclerosis, significantly \" \n",
    "    \"compromising kidney filtration function.\"\n",
    ")\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a helpful, knowledgeable assistant who will explain the \"\n",
    "    \"morphology of the cell image visible in the histopathology tissue patch. \"\n",
    "    \"You must utilize the visual cues in the images and textual cues from given \"\n",
    "    \"metadata. Also, include only ONE caption per image. Separate each caption \" \n",
    "    \"with the image number like `[Image #]`. Here is a sample caption for your reference: \" \n",
    "    f\"'{example_caption}'\"\n",
    ")\n",
    "\n",
    "# Cell and Tissue Metadata\n",
    "#  - [0]: cell type \n",
    "#  - [1]: cell disease state \n",
    "#  - [2]: tissue\n",
    "#  - [3]: tissue disease state\n",
    "#  - [4]: source (mouse or human)\n",
    "#  - [5]: st technology\n",
    "def cell_tissue_user_prompt(metadata):\n",
    "    return (\n",
    "        \"Generate a concise, biologically accurate caption that describes the cellular morphology, including \"\n",
    "        \"shape, size, structure, and function of the cell in the histopathology tissue patch. The \" \n",
    "        f\"single cell image is a {'cancerous' if metadata[1]=='1' else 'non-cancerous'} {metadata[0]} cell. \"\n",
    "        f\"It is located in the {metadata[4]}\\'s {metadata[2]}, \"\n",
    "        f\"which is {'cancerous' if metadata[3]=='1' else 'not cancerous'}. The images were \"\n",
    "        f\"obtained using {metadata[5]} spatial transcriptomics technology.\"\n",
    "    )\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9YdA5kvUruH",
    "outputId": "f0a8ed9a-53a9-4413-c4af-999474a6ea58"
   },
   "outputs": [],
   "source": [
    "def load_data_from_xenium_single_folder(folder_path):\n",
    "    all_cell_ids = []\n",
    "    all_metadata = []\n",
    "    all_prompts = []\n",
    "    all_images = []\n",
    "\n",
    "    required_cols = [\"cell_id\", \"cell_type\", \"cell_disease_state\", \"tissue_disease_state\"]\n",
    "\n",
    "    # Parse fixed metadata from folder name\n",
    "    base_name = os.path.basename(folder_path.rstrip(\"/\"))\n",
    "    parts = base_name.split(\"_\")\n",
    "    if len(parts) < 3:\n",
    "        raise ValueError(f\"Folder name '{base_name}' must be like 'Xenium_Mouse_Femur'\")\n",
    "\n",
    "    st_tech = parts[0]\n",
    "    source = parts[1]\n",
    "    tissue = parts[2]\n",
    "\n",
    "    sample_dirs = sorted([\n",
    "        f for f in os.listdir(folder_path)\n",
    "        if os.path.isdir(os.path.join(folder_path, f))\n",
    "    ])\n",
    "\n",
    "    print(f\"ðŸ“‚ Found {len(sample_dirs)} samples in {base_name}\")\n",
    "\n",
    "    for sample_id in sample_dirs:\n",
    "        sample_path = os.path.join(folder_path, sample_id)\n",
    "        cell_tif = os.path.join(sample_path, \"cell.tif\")\n",
    "        tissue_tif = os.path.join(sample_path, \"patch.tif\")\n",
    "        attr_csv = os.path.join(sample_path, \"attributes.csv\")\n",
    "\n",
    "        if not all(os.path.exists(p) for p in [cell_tif, tissue_tif, attr_csv]):\n",
    "            print(f\"â›” Missing files in {sample_id}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(attr_csv)\n",
    "            if df.empty:\n",
    "                continue\n",
    "            row = df.iloc[0]\n",
    "            if not all(col in row for col in required_cols):\n",
    "                print(f\"â›” Missing columns in {sample_id}\")\n",
    "                continue\n",
    "\n",
    "            cell_id = str(row[\"cell_id\"])\n",
    "            cell_type = str(row[\"cell_type\"])\n",
    "            cell_dis = str(row[\"cell_disease_state\"])\n",
    "            tissue_dis = str(row[\"tissue_disease_state\"])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"â›” Error reading {sample_id}/attributes.csv: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Convert .tif to .png\n",
    "        try:\n",
    "            cell_png = convert_tif_to_png(cell_tif)\n",
    "            tissue_png = convert_tif_to_png(tissue_tif)\n",
    "        except Exception as e:\n",
    "            print(f\"â›” TIFF conversion failed for {sample_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Compose metadata and prompt\n",
    "        metadata = [\n",
    "            cell_type,\n",
    "            cell_dis,\n",
    "            tissue,\n",
    "            tissue_dis,\n",
    "            source,\n",
    "            st_tech\n",
    "        ]\n",
    "\n",
    "        prompt = cell_tissue_user_prompt(metadata)\n",
    "\n",
    "        all_cell_ids.append(cell_id)\n",
    "        all_metadata.append(metadata)\n",
    "        all_prompts.append(prompt)\n",
    "        all_images.append([cell_png, tissue_png])\n",
    "\n",
    "    print(f\"âœ… Loaded {len(all_prompts)} samples from {base_name}\")\n",
    "    return all_cell_ids, all_metadata, all_prompts, all_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(cell_ids, metadata_list, prompts, images, batch_size=10):\n",
    "    batches = []\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch = (\n",
    "            cell_ids[i:i+batch_size],\n",
    "            metadata_list[i:i+batch_size],\n",
    "            prompts[i:i+batch_size],\n",
    "            images[i:i+batch_size]\n",
    "        )\n",
    "        batches.append(batch)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def append_to_csv(csv_path, cell_ids, metadata_list, captions):\n",
    "    header = [\"cell_id\", \"cell-type\", \"cell disease state\", \"tissue\",\n",
    "              \"tissue disease state\", \"source\", \"st technology\", \"caption\"]\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write header once\n",
    "        if not file_exists:\n",
    "            writer.writerow(header)\n",
    "\n",
    "        for cid, meta, cap in zip(cell_ids, metadata_list, captions):\n",
    "            writer.writerow([cid] + meta + [cap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_llm_request(client, system_prompt, prompt_list, image_lists):\n",
    "    \"\"\"\n",
    "    Sends a single GPT-4o request containing multiple (prompt + 2 images) entries.\n",
    "\n",
    "    Parameters:\n",
    "        client: OpenAI client\n",
    "        system_prompt: str, system message with task definition\n",
    "        prompt_list: list of strings, user prompts for each cell-tissue pair\n",
    "        image_lists: list of [cell_img_path, tissue_img_path] for each entry\n",
    "\n",
    "    Returns:\n",
    "        response: OpenAI API response\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    user_content = []\n",
    "\n",
    "    for i, (prompt, image_pair) in enumerate(zip(prompt_list, image_lists)):\n",
    "        cell_img_path, tissue_img_path = image_pair\n",
    "\n",
    "        # Add prompt text with identifier\n",
    "        user_content.append({\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"[Image Pair {i+1}] {prompt}\"\n",
    "        })\n",
    "\n",
    "        # Add cell image\n",
    "        user_content.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{encode_image(cell_img_path)}\"\n",
    "            }\n",
    "        })\n",
    "\n",
    "        # Add tissue image\n",
    "        user_content.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{encode_image(tissue_img_path)}\"\n",
    "            }\n",
    "        })\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            messages=messages\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch request: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Uj_-yTrY5kwD"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def run_captioning_pipeline_single_output(root_dir, batch_size=10):\n",
    "    \"\"\"\n",
    "    Runs the captioning pipeline for a single organ directory.\n",
    "    Outputs a single CSV file named captions_{source}_{organ}.csv.\n",
    "    \"\"\"\n",
    "\n",
    "    # === Step 1: Load data ===\n",
    "    cell_ids, metadata_list, prompts, image_paths = load_data_from_xenium_single_folder(root_dir)\n",
    "    print(f\"âœ… Loaded {len(prompts)} entries from {root_dir}\")\n",
    "\n",
    "    # === Step 2: Derive output filename from folder name ===\n",
    "    folder_name = Path(root_dir.rstrip(\"/\")).name\n",
    "    parts = folder_name.split(\"_\")\n",
    "    if len(parts) < 3:\n",
    "        raise ValueError(f\"Folder name '{folder_name}' must be of the form 'Xenium_Source_Organ'\")\n",
    "\n",
    "    source = parts[1].lower()\n",
    "    organ = parts[2].lower()\n",
    "    csv_path = f\"captions_{source}_{organ}.csv\"\n",
    "\n",
    "    # === Step 3: Create batches ===\n",
    "    batches = create_batches(cell_ids, metadata_list, prompts, image_paths, batch_size=batch_size)\n",
    "\n",
    "    responses = []\n",
    "    token_counts = []\n",
    "\n",
    "    # === Step 4: Process each batch ===\n",
    "    for idx, (cid_batch, meta_batch, prompt_batch, image_batch) in enumerate(batches):\n",
    "        print(f\"\\nðŸŒ€ Processing Batch #{idx + 1}/{len(batches)}\")\n",
    "\n",
    "        response = batch_llm_request(client, system_prompt, prompt_batch, image_batch)\n",
    "        responses.append(response)\n",
    "\n",
    "        if response:\n",
    "            text = response.choices[0].message.content\n",
    "\n",
    "            # Split captions by newlines\n",
    "            captions = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "\n",
    "            if len(captions) != len(cid_batch):\n",
    "                print(f\"âš ï¸ Warning: Mismatch in caption count (got {len(captions)}, expected {len(cid_batch)}). Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            append_to_csv(csv_path, cid_batch, meta_batch, captions)\n",
    "            print(f\"âœ… Saved Batch #{idx + 1} to {csv_path}\")\n",
    "\n",
    "            if hasattr(response, \"usage\"):\n",
    "                tokens = response.usage.total_tokens\n",
    "                token_counts.append(tokens)\n",
    "                print(f\"ðŸ”¢ Tokens used: {tokens}\")\n",
    "        else:\n",
    "            print(f\"âŒ GPT call failed for Batch #{idx + 1}\")\n",
    "\n",
    "    return responses, token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "maiW23trXSOo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Found 1000 samples in Xenium_Mouse_Femur\n",
      "âœ… Loaded 1000 samples from Xenium_Mouse_Femur\n",
      "\n",
      "ðŸŒ€ Processing Batch #1/100\n",
      "âœ… Saved Batch #1 to captions_mouse_femur.csv\n",
      "ðŸ”¢ Tokens used: 6970\n",
      "\n",
      "ðŸŒ€ Processing Batch #2/100\n",
      "âœ… Saved Batch #2 to captions_mouse_femur.csv\n",
      "ðŸ”¢ Tokens used: 6824\n",
      "\n",
      "ðŸŒ€ Processing Batch #3/100\n",
      "âœ… Saved Batch #3 to captions_mouse_femur.csv\n",
      "ðŸ”¢ Tokens used: 6812\n",
      "\n",
      "ðŸŒ€ Processing Batch #4/100\n",
      "âš ï¸ Warning: Mismatch in caption count (got 20, expected 10). Skipping batch.\n",
      "\n",
      "ðŸŒ€ Processing Batch #5/100\n",
      "âœ… Saved Batch #5 to captions_mouse_femur.csv\n",
      "ðŸ”¢ Tokens used: 6837\n",
      "\n",
      "ðŸŒ€ Processing Batch #6/100\n",
      "âœ… Saved Batch #6 to captions_mouse_femur.csv\n",
      "ðŸ”¢ Tokens used: 6852\n",
      "\n",
      "ðŸŒ€ Processing Batch #7/100\n",
      "âœ… Saved Batch #7 to captions_mouse_femur.csv\n",
      "ðŸ”¢ Tokens used: 6784\n",
      "\n",
      "ðŸŒ€ Processing Batch #8/100\n",
      "âœ… Saved Batch #8 to captions_mouse_femur.csv\n",
      "ðŸ”¢ Tokens used: 6729\n",
      "\n",
      "ðŸŒ€ Processing Batch #9/100\n",
      "âœ… Saved Batch #9 to captions_mouse_femur.csv\n",
      "ðŸ”¢ Tokens used: 6763\n",
      "\n",
      "ðŸŒ€ Processing Batch #10/100\n",
      "âœ… Saved Batch #10 to captions_mouse_femur.csv\n",
      "ðŸ”¢ Tokens used: 6881\n",
      "\n",
      "ðŸŒ€ Processing Batch #11/100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "responses, token_counts = run_captioning_pipeline_single_output(root_path, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
